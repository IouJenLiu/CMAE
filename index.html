<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" integrity="sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2" crossorigin="anonymous">

    <title>CMAE</title>
  </head>
  <body>
  	<div style="text-align:center;">
		<div id="intro" style="width: 100%; padding:40px; text-align:center;">
	        <h1>Cooperative Exploration for Multi-Agent Deep Reinforcement Learning</h1>
	    </div>
		<div class="container">
		  <div class="row">
		    <div class="col-sm">
		      <a href="https://ioujenliu.github.io/"><h4> Iou-Jen Liu </h4></a>    
		    </div>
		    <div class="col-sm">
		      <a href="https://unnat.github.io/"><h4> Unnat Jain</h4></a> 
		    </div>
		    <div class="col-sm">
		      <a href="https://raymondyeh07.github.io/"><h4> Raymond A. Yeh</h4></a> 
		    </div>
		    <div class="col-sm">
		      <a href="http://www.alexander-schwing.de/"><h4> Alexander G. Schwing </h4></a> 
		    </div>
		  </div>
		  <p></p>
		  <div class="row">
		  	<div class="col-lg">
		   	<h4> University of Illinois at Urbana-Champaign (UIUC) </h4>
		    </div>
		  </div>
		  <div class="row">
		  	<div class="col-lg">
		   	<h4> International Conference on Machine Learning (ICML), 2021 </h4>
		    </div>
		  </div>
		  <!--
		  <div class="row">
		  			    <div class="col-lg">
		    <center><h2><strong>
	<a href="https://papers.nips.cc/paper/2020/file/c6447300d99fdbf4f3f7966295b8b5be-Paper.pdf">Paper</a> |
	<a href="https://github.com/IouJenLiu/HTS-RL">Code</a> |
	<a href="./files/presentation.ppsm">Slides</a> |
    <a href="./files/bib.txt">Bibtex</a> </strong> </h2></center> 
			</div>
		  </div>
		  <br>
		  
		  <div class="row">
		  	<div class="col-lg">
		  	<img src="./figs/flow_all_v3.png" class="img-fluid">
		  	</div>
		  </div>

		  <br><br>
		  <div class="row">
		  	<div class="col-sm">
		  		<h2> Abstract </h2>
		  	</div>
		  </div>
		  <div class="row">
		  	<div style="font-size:16px"><p align="justify">
		  		Various parallel actor-learner methods reduce long training times for deep reinforcement learning. Synchronous methods enjoy training stability while having lower data throughput. In contrast, asynchronous methods achieve high throughput but suffer from stability issues and lower sample efficiency due to ‘stale policies’. To combine the advantages of both methods we propose High-Throughput Synchronous Deep Reinforcement Learning (HTS-RL). In HTS-RL, we perform learning and rollouts concurrently, devise a system design which avoids ‘stale policies’ and ensure that actors interact with environment replicas in an asynchronous manner while maintaining full determinism. We evaluate our approach on Atari games and the Google Research Football environment. Compared to synchronous baselines, HTS-RL is 2 − 6X faster. Compared to state-of-the-art asynchronous methods, HTS-RL has competitive throughput and consistently achieves higher average episode rewards.
		  	</p>
		  	</div>
		  </div>

		  <br><br>
		  <div class="row">
		  	<div class="col-sm">
		  		<h2> Materials </h2><p></p>
		  	</div>
		  </div>
		  <div class="row">
		    <div class="col-lg">
		    	<a href="https://papers.nips.cc/paper/2020/file/c6447300d99fdbf4f3f7966295b8b5be-Paper.pdf">
          			<img src="figs/paper_thumb.png" style="height:270px" class="img-fluid" alt="Responsive image">
          		</a>
          	  <br>
		      <a href="https://papers.nips.cc/paper/2020/file/c6447300d99fdbf4f3f7966295b8b5be-Paper.pdf"><button type="button" class="btn btn-secondary">Paper</button></a>           
		    </div>
		    <div class="col-lg">
		      <a href="./files/poster.pdf">
          			<img src="figs/poster_thumb.png" style="height:270px" class="img-fluid" alt="Responsive image">
          		</a>
          	  <br>
		      <a href="./files/poster.pdf"><button type="button" class="btn btn-secondary">Poster</button></a>   
		    </div>
		    <div class="col-lg">
		      <a href="https://github.com/IouJenLiu/HTS-RL">
		    		<img src="figs/code_thumb.jpg" style="height:270px" class="img-fluid" alt="Responsive image">
		    	</a>
		      <br>
		      <a href="https://github.com/IouJenLiu/HTS-RL"><button type="button" class="btn btn-secondary">Code</button></a>  
		    </div>
		  </div>

		  <br><br>
		  <div class="row">
		  	<div class="col-lg">
		  		<h2> Presentation </h2> <p></p>
		  		<div class="embed-responsive embed-responsive-16by9">
				  <video width="800" height="480" controls preload="auto"><source src="./files/HTS-RL.mp4" type="video/mp4"></video>
				</div>
		  	</div>
		  </div>

          <br><br>
		  <div class="row">
		  	<div class="col-sm">
		  		<h2> Citation </h2>
		  		    <pre align="left">
@inproceedings{LiuNEURIPS2020,
  author = {I.-J. Liu and R.~A. Yeh and A.~G. Schwing},
  title = {{High-Throughput Synchronous Deep RL}},
  booktitle = {Proc. NeurIPS},
  year = {2020},
}
</pre>
			</div>
		  </div>

		  <div class="row">
		  	<div class="col-sm">
		  		<h2> Acknowledgement </h2>
		  		<p align="left">
	This work is supported in part by NSF under Grant # 1718221, 2008387 and MRI #1725729, NIFA award 2020-67021-32799, UIUC, Samsung, Amazon, 3M, Cisco Systems Inc. (Gift Award CG 1377144), and a Google PhD Fellowship to RY. We thank Cisco for access to the Arcetri cluster.
    <br><br>
		  	</div>
		  </div>		  

		</div>
	</div>



	<div id="intro" style="width: 100%; padding:50px; text-align:center;">
	        <h1></h1>
	</div>

    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ho+j7jyWK8fNQe+A12Hb8AhRq26LrZ/JpcUGGOn+Y7RsweNrtN/tE3MoK7ZeZDyx" crossorigin="anonymous"></script>
    -->
  </body>
</html>
