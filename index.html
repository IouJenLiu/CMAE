<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" integrity="sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2" crossorigin="anonymous">

    <title>CMAE</title>
  </head>
  <body>
  	<div style="text-align:center;">
		<div id="intro" style="width: 100%; padding:40px; text-align:center;">
	        <h1>Cooperative Exploration for <br> Multi-Agent Deep Reinforcement Learning</h1>
	    </div>
		<div class="container">
		  <div class="row">
		    <div class="col-sm">
		      <a href="https://ioujenliu.github.io/"><h4> Iou-Jen Liu </h4></a>    
		    </div>
		    <div class="col-sm">
		      <a href="https://unnat.github.io/"><h4> Unnat Jain</h4></a> 
		    </div>
		    <div class="col-sm">
		      <a href="https://raymondyeh07.github.io/"><h4> Raymond A. Yeh</h4></a> 
		    </div>
		    <div class="col-sm">
		      <a href="http://www.alexander-schwing.de/"><h4> Alexander G. Schwing </h4></a> 
		    </div>
		  </div>
		  <p></p>
		  <div class="row">
		  	<div class="col-lg">
		   	<h4> University of Illinois at Urbana-Champaign (UIUC) </h4>
		    </div>
		  </div>
		  <div class="row">
		  	<div class="col-lg">
		   	<h4> International Conference on Machine Learning (ICML), 2021 </h4>
		    </div>
		  </div>
		  
		  <div class="row">
		  			    <div class="col-lg">
		    <center><h2><strong>
	<a href="http://proceedings.mlr.press/v139/liu21j/liu21j.pdf">Paper</a> |
	<!-- <a href="https://github.com/IouJenLiu/HTS-RL">Code</a> | -->
	<a href="./files/talk_slides.pdf">Slides</a> |
    <a href="./files/bib.txt">Bibtex</a> </strong> </h2></center> 
			</div>
		  </div>
		  <br>
		  
		  <div class="row">
		  	<div class="col-lg">
		  	<img src="./files/flow.png" class="img-fluid" style="width:509px;height:400px;">
		  	</div>
		  </div>

		  <br><br>
		  <div class="row">
		  	<div class="col-sm">
		  		<h2> Abstract </h2>
		  	</div>
		  </div>
		  <div class="row">
		  	<div style="font-size:16px"><p align="justify">
		  		Exploration is critical for good results in deep reinforcement learning and has attracted much attention. However, existing multi-agent deep reinforcement learning algorithms still use mostly
				noise-based techniques. Very recently, exploration methods that consider cooperation among
				multiple agents have been developed. However,
				existing methods suffer from a common challenge: agents struggle to identify states that are
				worth exploring, and hardly coordinate exploration efforts toward those states. To address
				this shortcoming, in this paper, we propose cooperative multi-agent exploration (CMAE): agents
				share a common goal while exploring. The goal
				is selected from multiple projected state spaces
				via a normalized entropy-based technique. Then,
				agents are trained to reach this goal in a coordinated manner. We demonstrate that CMAE
				consistently outperforms baselines on various
				tasks, including a sparse-reward version of the
				multiple-particle environment (MPE) and the
				Starcraft multi-agent challenge (SMAC).
		  	</p>
		  	</div>
		  </div>

		  <br><br>
		  <div class="row">
		  	<div class="col-sm">
		  		<h2> Materials </h2><p></p>
		  	</div>
		  </div>
		  <div class="row">
		    <div class="col-lg">
		    	<a href="http://proceedings.mlr.press/v139/liu21j/liu21j.pdf">
          			<img src="files/paper_thumb.png" style="height:270px" class="img-fluid" alt="Responsive image">
          		</a>
          	  <br>
		      <a href="http://proceedings.mlr.press/v139/liu21j/liu21j.pdf"><button type="button" class="btn btn-secondary">Paper</button></a>           
		    </div>
		    <div class="col-lg">
		      <a href="./files/poster.pdf">
          			<img src="files/poster_thumb.png" style="width:400px" class="img-fluid" alt="Responsive image">
          		</a>
          	  <br>
		      <a href="./files/poster.pdf"><button type="button" class="btn btn-secondary">Poster</button></a>   
		    </div>
		   <!-- <div class="col-lg">
		      <a href="https://github.com/IouJenLiu/HTS-RL">
		    		<img src="figs/code_thumb.jpg" style="height:270px" class="img-fluid" alt="Responsive image">
		    	</a>
		      <br>
		      <a href="https://github.com/IouJenLiu/HTS-RL"><button type="button" class="btn btn-secondary">Code</button></a>  
		    </div> -->
		  </div> 

		  <br><br>
		  <!--<div class="row">
		  	<div class="col-lg">
		  		<h2>Presentation</h2>
			    <div class=text-center>
			    <iframe width="560" height="315" src="https://www.youtube.com/embed/rQZHawgqgsk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
			    </div>
		  	</div>
		  </div>-->

          <br><br>
		  <div class="row">
		  	<div class="col-sm">
		  		<h2> Citation </h2>
		  		    <pre align="left">
@inproceedings{LiuICML2021,
  author = {I.-J. Liu and U. Jain and R.~A. Yeh and A.~G. Schwing},
  title = {{Cooperative Exploration for Multi-Agent Deep Reinforcement Learning}},
  booktitle = {Proc. ICML},
  year = {2021},
}
</pre>
			</div>
		  </div>

		  <div class="row">
		  	<div class="col-sm">
		  		<h2> Acknowledgement </h2>
		  		<p align="left">
	This work is supported in part by NSF under Grant #1718221, 2008387, 2045586, and MRI #1725729, UIUC, Samsung, Amazon, 3M, and Cisco Systems Inc. RY is supported by a Google Fellowship.
    <br><br>
		  	</div>
		  </div>		  

		</div>
	</div>



	<div id="intro" style="width: 100%; padding:50px; text-align:center;">
	        <h1></h1>
	</div>

    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ho+j7jyWK8fNQe+A12Hb8AhRq26LrZ/JpcUGGOn+Y7RsweNrtN/tE3MoK7ZeZDyx" crossorigin="anonymous"></script>
   
  </body>
</html>
